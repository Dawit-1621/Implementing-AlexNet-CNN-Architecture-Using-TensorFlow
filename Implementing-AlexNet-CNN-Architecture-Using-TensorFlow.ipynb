{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 1176s 7us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AlexNet**<br>\n",
    "The work that perhaps could be credited with sparking renewed interest in neural networks and the beginning of the dominance of deep learning in many computer vision applications was the 2012 paper by Alex Krizhevsky, et al. titled “ImageNet Classification with Deep Convolutional Neural Networks.”\n",
    "\n",
    "The paper describes a model later referred to as “AlexNet” designed to address the ImageNet Large Scale Visual Recognition Challenge or ILSVRC-2010 competition for classifying photographs of objects into one of 1,000 different categories.\n",
    "\n",
    "The ILSVRC was a competition held from 2011 to 2016, designed to spur innovation in the field of computer vision. Before the development of AlexNet, the task was thought very difficult and far beyond the capability of modern computer vision methods. AlexNet successfully demonstrated the capability of the convolutional neural network model in the domain, and kindled a fire that resulted in many more improvements and innovations, many demonstrated on the same ILSVRC task in subsequent years. More broadly, the paper showed that it is possible to develop deep and effective end-to-end models for a challenging problem without using unsupervised pretraining techniques that were popular at the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 73, 73, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 36, 36, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 36, 36, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 256)       2973952   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 11, 11, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 9, 9, 384)         1536      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 256)         884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              9441280   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 3003      \n",
      "=================================================================\n",
      "Total params: 36,471,363\n",
      "Trainable params: 36,450,227\n",
      "Non-trainable params: 21,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Convolution Step 1\n",
    "classifier.add(Convolution2D(96, 11, strides = (4, 4), padding = 'valid', input_shape=(300, 300, 3), activation = 'relu'))\n",
    "\n",
    "# Max Pooling Step 1\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# Convolution Step 2\n",
    "classifier.add(Convolution2D(256, 11, strides = (1, 1), padding='valid', activation = 'relu'))\n",
    "\n",
    "# Max Pooling Step 2\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding='valid'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# Convolution Step 3\n",
    "classifier.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# Convolution Step 4\n",
    "classifier.add(Convolution2D(384, 3, strides = (1, 1), padding='valid', activation = 'relu'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# Convolution Step 5\n",
    "classifier.add(Convolution2D(256, 3, strides=(1,1), padding='valid', activation = 'relu'))\n",
    "\n",
    "# Max Pooling Step 3\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'valid'))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "# Flattening Step\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Full Connection Step\n",
    "classifier.add(Dense(units = 4096, activation = 'relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dense(units = 4096, activation = 'relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dense(units = 1000, activation = 'relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(Dense(units = 3, activation = 'softmax'))\n",
    "classifier.summary()\n",
    "\n",
    "\n",
    "# Compiling the CNN\n",
    "#classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer=optimizers.SGD(lr=0.001, momentum=0.9, decay=0.005),\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
